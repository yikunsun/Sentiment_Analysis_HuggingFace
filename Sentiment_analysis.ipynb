{"cells":[{"cell_type":"markdown","metadata":{"id":"geyfdnWqyeA1"},"source":["# Binary sentiment classification with BERT uncased model\n","For this project, I'm going to fine-tune [a pretrained BERT uncased model](https://huggingface.co/bert-base-uncased) shared on the Hugging Face Hub with [IMDB movie reviews data](https://huggingface.co/datasets/imdb) and use the fine-tuned mdoel to classify the sentiment of movie reviews.\n","\n","Most of the functions used come from **Hugging Face's Transformers library**, and the deep learning framework used is **PyTorch**."]},{"cell_type":"markdown","metadata":{"id":"7nO4qEfJyeA4"},"source":["## 1. Download the IMDB movie reviews dataset and process the data"]},{"cell_type":"markdown","metadata":{"id":"-YBKUsf8yeA4"},"source":["### 1.1 Download the dataset from the Hugging Face Hub\n","Downloading a dataset shared on the Hub is made very simple with the `Datasets` library, which downloads and caches the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eN6AqIv3yeA5"},"outputs":[],"source":["# Download the IMDB dataset with load_dataset()\n","from datasets import load_dataset, Dataset, DatasetDict\n","\n","raw_datasets = load_dataset('imdb')"]},{"cell_type":"markdown","metadata":{"id":"E-rGn3pRyeA6"},"source":["IMDB dataset has **three splits**: train, test, and unsupervised. For this project, I will only need train and test splits.\n","\n","Each split has **two fields**, text and label:\n","- Text contains movie reviews\n","- Label is a binary value with 0 indicating negative review and 1 indicating positive reivew."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GD2IavGFyeA6","executionInfo":{"status":"ok","timestamp":1694662997745,"user_tz":420,"elapsed":565,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"4427a8e2-2d52-4481-8c07-62b488df12f6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 25000\n","    })\n","    unsupervised: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 50000\n","    })\n","})"]},"metadata":{},"execution_count":11}],"source":["# IMDB dataset has 3 splits: train, test, unsupervised\n","# Each split only has two fields\n","# For this project, I only need train and test\n","raw_datasets"]},{"cell_type":"code","source":["# Keep 1000 records from the unsupervised dataset\n","# Use the fine-tuned model to classify the sentiment of these reviews later\n","# Randomly select 1000 records\n","import random\n","random.seed(42)\n","random_1000 = [random.randint(0, 49999) for _ in range(1000)]\n","unsupervised_reviews = Dataset.from_dict(raw_datasets['unsupervised'][random_1000])"],"metadata":{"id":"04bohiU_yU2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMkNb2SJyeA7"},"outputs":[],"source":["# Keep only 500 records in training and testing datasets to make training and evaluating faster\n","# Randomly select 500 records\n","random.seed(42)\n","random_500 = [random.randint(0, 24999) for _ in range(500)]\n","train_dataset = Dataset.from_dict(raw_datasets['train'][random_500])\n","test_dataset = Dataset.from_dict(raw_datasets['test'][random_500])\n","raw_datasets = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q81Abz5CyeA8","executionInfo":{"status":"ok","timestamp":1694670047909,"user_tz":420,"elapsed":1,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"308156cf-1c32-42f5-afc8-f61049bc9b99"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 500\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 500\n","    })\n","})"]},"metadata":{},"execution_count":68}],"source":["# Examine raw_datasets to ensure data has been properly sliced\n","raw_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdrWzpsEyeA8","executionInfo":{"status":"ok","timestamp":1694670050581,"user_tz":420,"elapsed":420,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"3462fcf9-a0ba-4f77-a090-df5928aa860a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'text': 'Arguably this is a very good \"sequel\", better than the first live action film 101 Dalmatians. It has good dogs, good actors, good jokes and all right slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, is now a lover of dogs and very kind to them. Many, including Chloe Simon, owner of one of the dogs that Cruella once tried to kill, do not believe this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have given birth to three cute dalmatian puppies! Little Dipper, Domino and Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt (another baddie, the name should give a clue), this is a good family film with excitement and lots more!! One downfall of this film is that is has a lot of painful slapstick, but not quite as excessive as the last film. This is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)',\n"," 'label': 1}"]},"metadata":{},"execution_count":69}],"source":["# Check what the data looks like\n","raw_datasets['train'][0]"]},{"cell_type":"markdown","metadata":{"id":"-2RkSkLzyeA8"},"source":["### 1.2 Process data"]},{"cell_type":"markdown","metadata":{"id":"UTD1qSLsyeA9"},"source":["#### 1.2.1 Tokenize text\n","I'm going to fine-tune a pretrained BERT uncased model. Because transformer models can't directly process text, I need to convert movie reviews from text into numerical representations that can be fed into the model.\n","\n","To accomplish this, I will be using a **tokenizer**, which handles the following tasks:\n","- Splitting text into words, subwords, or symbols, referred to as tokens\n","- Mapping tokens to integers\n","- Incorporating additional inputs that might be beneficial for the model\n","\n","Setting up the tokenizer is straightforward using the `AutoTokenizer` class and its `from_pretrained()` method. All I need to do is specify the **checkpoint name** of the pretrained BERT uncased model, and it will load the corresponding pretrained tokenizer. Using this tokenizer will ensure that text is processed in the same manner as during the model's pretraining."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSsPFH9gyeA9"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# Checkpoint name of the pretrained BERT uncased model\n","checkpoint = 'bert-base-uncased'\n","\n","# Load the corresponding pretrained tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"Lh9e7K4vyeA9"},"source":["Define a function to tokenize movie reviews with the following setting:\n","- `truncation=True` to ensure that input sequences do not exceed the length limit of the BERT uncased model.\n","\n","Then, use `Dataset.map()` method to apply this function to each element of the dataset with the option:\n","- `batched=True`, which can expedite tokenization by applying the function to multiple elements of the dataset simultaneously."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_WLEYleDyeA9"},"outputs":[],"source":["def tokenize_function(example):\n","    return tokenizer(example['text'], truncation=True)"]},{"cell_type":"markdown","metadata":{"id":"4hYxRNFUyeA9"},"source":["The tokenized dataset includes three new fields:\n","- **input_ids**: Unique numbers assigned to each word, subword, or symbol in a sentence. They assit the model in understanding the words.\n","\n","- **token_type_ids**: Numbers indicating different sentences. This becomes more valuable when classifying pairs of sentences. For binary sentiment classification, these IDs are always set to 0.\n","\n","- **attention_mask**: Tensors with the exact same shape as the input IDs tensor, consisting of 0s and 1s:\n","    - 1s indicate the corresponding tokens should be attended to\n","    - 0s indicate the corresponding tokens should not be attended to"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["6e7a6bc709534a55a1db9f83957a4ed0","b05fcef5a277453d8988a5085b5f1252","897ac4eeffeb4f81a9804f919496a7c9","6c02f4d1129d4548a6dff1789b4fe1a4","74ea3b354bdd4aecac9fbc4cc661c0f4","08cc9c74ab974ff18514575ba33cd76d","e282efd44e874ff1a67f0e1d46de0ad3","57e5ec4c29c94143bd6490b073bb5ef7","9d34bd4e3a874d4480c325a09e6f7167","dd9fcd2463c546eda6b5b66daf8b119e","325bedc92f6846b2995112ea9d0e4a05","727eba7442e9405b92aeb14bb07c2b8d","b402c5a8635044d6bf44c66698468e0f","379e725cc61043b684b4a155177d6cb9","685ac324258a4d9da88a2f59f08d20cf","03ce619f15624182af7f474d6711c4a6","5fc03a6b0109409bbef2012f5ce79e30","50921b78d99d4948bdfd7415eba8c1a1","b11e883e01284b629964499ea6527eae","80d1d6402474492ba5d8a7229cb5b8f5","4750ff47eebe4abdb2a3977792c59c76","47fb460413cd474f8948b0c8137f15f8"]},"id":"kqvLBJ9wyeA9","executionInfo":{"status":"ok","timestamp":1694670061510,"user_tz":420,"elapsed":2000,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"8b6c1946-0fa1-45d5-b7f7-e44d56867a40"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e7a6bc709534a55a1db9f83957a4ed0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"727eba7442e9405b92aeb14bb07c2b8d"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 500\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 500\n","    })\n","})"]},"metadata":{},"execution_count":72}],"source":["tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","tokenized_datasets"]},{"cell_type":"markdown","metadata":{"id":"iTvq0vazyeA9"},"source":["#### 1.2.2 Dynamic padding\n","**Dynamic padding** is a technique used to standardize the length of all sequences in a batch or dataset. When fine-tuning the model, I need to pass batches of sequences through the model in tensor format. Without padding, sequences in one batch may have varying lengths, preventing the batch from being converted into a tensor.\n","\n","To address this issue, I need to use a **collate function**, which applies the appropriate amount of padding to sequences in a dataset that we want to batch together. The Transformers library offers a collate function through the `DataCollatorWithPadding` class. This class requires a tokenizer when instantiated, and the input should be in dictionary format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QyokoMeyeA9"},"outputs":[],"source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"OIxgGCW4yeA9"},"source":["## 2. Prepare for modeling"]},{"cell_type":"markdown","metadata":{"id":"Nbyw0QshyeA9"},"source":["### 2.1 Process tokenized dataset\n","There are 3 processings to apply to `tokenized_datasets`:\n","1. Remove columns that can't be fed to the model. Only need to remove \"text\" column.\n","\n","2. Rename the \"label\" column as \"labels\" because the model's `forward()` method expects the argument to be named \"labels\".\n","\n","3. Convert the format of datasets from lists to tensors since the model can't process lists of data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25MxIcyiyeA-"},"outputs":[],"source":["tokenized_datasets = tokenized_datasets.remove_columns(['text'])\n","tokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\n","tokenized_datasets.set_format('torch')"]},{"cell_type":"markdown","metadata":{"id":"S6on__mMyeA-"},"source":["### 2.2 Prepare DataLoaders\n","DataLoaders will be used to iterate over batches when fine-tuning the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j553pDd_yeA-"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(\n","    tokenized_datasets['train'], shuffle=True, batch_size=16, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets['test'], batch_size=16, collate_fn=data_collator\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_j2RK-PyeA-","executionInfo":{"status":"ok","timestamp":1694670073607,"user_tz":420,"elapsed":418,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"63cf7a52-569b-4a5f-809d-e834210d806a"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'labels': torch.Size([16]),\n"," 'input_ids': torch.Size([16, 512]),\n"," 'token_type_ids': torch.Size([16, 512]),\n"," 'attention_mask': torch.Size([16, 512])}"]},"metadata":{},"execution_count":76}],"source":["# Inspect a batch in train_dataloader to verify its preparation\n","for batch in train_dataloader:\n","    break\n","{k: v.shape for k, v in batch.items()}"]},{"cell_type":"markdown","metadata":{"id":"Vdc81mEByeA-"},"source":["### 2.3 Set up optimizer\n","For **optimizer**, I will use the default optimizer `AdamW` in the `Trainer` class. AdamW is similar to Adam but incorporates weight decay regularization.\n","\n","Before defining the optimizer, I need to load the pretrained BERT uncased model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkuQRjdsyeA-","executionInfo":{"status":"ok","timestamp":1694670901635,"user_tz":420,"elapsed":2832,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"1d468b67-80e6-4ef9-dcb4-7b48d47b1f0a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","\n","# num_labels=2 since the label is binary, either negative or positive\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFnNSmetyeA-"},"outputs":[],"source":["from transformers import get_scheduler\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n","\n","# Fine-tune the model for 3 epochs\n","num_epochs = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"D3GsHDkuyeA-","executionInfo":{"status":"ok","timestamp":1694670096958,"user_tz":420,"elapsed":706,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"20b0659d-e318-4619-c75b-6d2f0d9c2570"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":79}],"source":["# Set up device-agnostic code to utilize the GPU if it's available\n","import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"markdown","metadata":{"id":"ysxIV1PWyeA-"},"source":["## 3. Modeling"]},{"cell_type":"markdown","metadata":{"id":"bCZUz7HbyeA-"},"source":["### 3.1 Baseline model\n","The pretrained BERT uncased model will serve as the baseline model.\n","\n","I need to calculate the classification accuracy of the baseline model and compare it to the fine-tuned model to assess the improvement. The Hugging Face `Evaluate` library offers access to numerous evaluation metrics and is user-friendly. I'll use it for evaluation.\n","\n","The classification accuracy of the baseline model is 0.476, meaning without fine-tuning, the BERT uncased model doesn't perform well."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-ZpT2bCyeA_","executionInfo":{"status":"ok","timestamp":1694670125171,"user_tz":420,"elapsed":22784,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"e16c05e4-aa5e-49d6-a1f6-593b886b899b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: {'accuracy': 0.476}\n"]}],"source":["import evaluate\n","# Load accuracy metric\n","metric = evaluate.load('accuracy')\n","# Send model to GPU\n","model.to(device)\n","# Set model in evaluation mode for faster evaluation\n","model.eval()\n","with torch.inference_mode():\n","    for batch in eval_dataloader:\n","        # Send data to GPU\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # Forward pass\n","        outputs = model(**batch)\n","        # Make predictions\n","        predictions = torch.argmax(outputs['logits'], dim=-1)\n","        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","    # Compute and print acccuracy\n","    print(f'Accuracy: {metric.compute()}')"]},{"cell_type":"markdown","metadata":{"id":"6Ua_OVHKyeA_"},"source":["### 3.2 Fine-tune the pretrained BERT uncased model\n","Need to set up training and evaluation loops as follows:\n","- Training loops for fine-tuning the pretrained model\n","\n","- Evaluation loops for assessing model performance"]},{"cell_type":"markdown","metadata":{"id":"MWlQpA-kyeA_"},"source":["Use `tqdm()` to include progress bars in the loops, allowing me to monitor the training and evaluation progress.\n","\n","The fine-tuned BERT uncased model achieves an accuracy of **0.772** on the testing dataset, a commendable performance given the limited training data of 500 movie reviews and 3 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102,"referenced_widgets":["ee013a12219c4d3ca421c2ab53c3c8b1","92ff64710e10404690d1ca87d6120fe5","23269ecb3b9145059b5b1a8426d219b4","a1831eb7e5ee42c5a2235f33e02e719e","7df80ba1301546e2a721bf32a0e63313","433cbb3ab2664d2d921a3f93063f5d08","2847758316ab4ff0ba82f89af54d5674","a14e5af82d6f4103858d1e62042d4d8d","447f139b18844fa89170951d780bdf2c","c999f6808acb4939b35d4b5a17bf7273","f49c79ffbe544bd99a900778cc1623cb"]},"id":"nTpf7TJiyeA_","executionInfo":{"status":"ok","timestamp":1694671166777,"user_tz":420,"elapsed":198884,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"a8954692-20d1-4cf4-80f8-3e7fdee694fa"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee013a12219c4d3ca421c2ab53c3c8b1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Accuracy: {'accuracy': 0.476}\n","Epoch: 2, Accuracy: {'accuracy': 0.476}\n","Epoch: 3, Accuracy: {'accuracy': 0.772}\n"]}],"source":["torch.manual_seed(42)\n","from tqdm.auto import tqdm\n","\n","progress_bar = tqdm(range(num_epochs))\n","\n","# Send model to GPU\n","model.to(device)\n","# Set model in training mode\n","model.train()\n","\n","for epoch in range(num_epochs):\n","    ### Training\n","    for batch in train_dataloader:\n","        # Send data to GPU\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        # Forward pass\n","        outputs = model(**batch)\n","        # Calculate loss\n","        loss = outputs.loss\n","        # Backward pass (backpropagation)\n","        loss.backward()\n","        # Step optimizer to update parameters\n","        optimizer.step()\n","        # Optimizer zero grad\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","\n","    ### Evaluation\n","    metric = evaluate.load('accuracy')\n","    # Set model in evaluation mode and calculate classification accuracy for every epoch\n","    model.eval()\n","    with torch.inference_mode():\n","        for batch in eval_dataloader:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = model(**batch)\n","            predictions = torch.argmax(outputs['logits'], dim=-1)\n","            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","        print(f'Epoch: {epoch+1}, Accuracy: {metric.compute()}')"]},{"cell_type":"code","source":["# Save the fine-tuned model to Google Drive for use in the future\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Specify a path to save the model\n","save_directory = '/content/drive/My Drive/Colab Notebooks/Models'\n","model.save_pretrained(save_directory)\n","\n","# Load saved model. Need to mount Google Drive again before loading\n","# model = AutoModelForSequenceClassification.from_pretrained(save_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obp6LwmDE2rx","executionInfo":{"status":"ok","timestamp":1694671467515,"user_tz":420,"elapsed":7909,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"46a14433-d987-4679-fbab-fc874b9b506e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"013FsjzFyeA_"},"source":["## 4. Use the fine-tuned BERT uncased model for sentiment classification"]},{"cell_type":"markdown","metadata":{"id":"HLAk-EY_yeBA"},"source":["### 4.1 Process data and prepare DataLoaders\n","Before using the model to classify sentiment, I need to **process movie reviews the same way** I did for the training and evaluation data:\n","\n","1. Tokenize movie reviews\n","2. Process tokenized data\n","3. Prepare DataLoaders"]},{"cell_type":"code","source":["# Tokenize movie reviews in unsupervised_reviews\n","tokenized_reviews = unsupervised_reviews.map(tokenize_function, batched=True)\n","tokenized_reviews"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["ae825b4b2d8c43cab6d7c91ba4a01ecb","b69c9d769d524f7a86b0471b3050217c","f867218b067d422b9fc6a1b81372580d","c7b4653313c1411995a5b538a9922284","27577641e18f476a930e9ea2f06e4486","eb89f8c7a74a441e98b92c235ce9d63c","9f27eb204fc94f998e0fb55a12fee00b","7f8cd7f9a4ca4ef7903ca7e3b952d39a","6a3fd2a41236470692d93dd79d4deebc","9fb7ea156697426fad7012cb4e9ca0fc","50e4f6a355df4659ab071a7a50789204"]},"id":"F1XhpnZXxk5c","executionInfo":{"status":"ok","timestamp":1694671635147,"user_tz":420,"elapsed":2373,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"c2046d4d-902a-440d-f3e1-371a636ffbbf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae825b4b2d8c43cab6d7c91ba4a01ecb"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 1000\n","})"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["# Process tokenized data\n","tokenized_reviews = tokenized_reviews.remove_columns(['text', 'label'])\n","tokenized_reviews.set_format('torch')"],"metadata":{"id":"Q5pF8xrt1rtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare DataLoaders\n","pred_dataloader = DataLoader(\n","    tokenized_reviews, batch_size=16, collate_fn=data_collator\n",")"],"metadata":{"id":"ky9xx3r42IiB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inspect a batch in pred_dataloader to verify its preparation\n","for batch in pred_dataloader:\n","    break\n","{k: v.shape for k, v in batch.items()}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JU0Wz2K2j7w","executionInfo":{"status":"ok","timestamp":1694671641905,"user_tz":420,"elapsed":3,"user":{"displayName":"YS","userId":"13814967776297417830"}},"outputId":"1e547a37-b01c-4d76-f0b4-6f93e50ee529"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': torch.Size([16, 512]),\n"," 'token_type_ids': torch.Size([16, 512]),\n"," 'attention_mask': torch.Size([16, 512])}"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","source":["### 4.2 Classify sentiment of movie reviews"],"metadata":{"id":"cn-YVuJw2tmQ"}},{"cell_type":"code","source":["# Send model to GPU\n","model.to(device)\n","# Set model in evaluation mode\n","model.eval()\n","# Create an empty tensor to store results\n","pred_tensor = torch.tensor([]).to(device)\n","with torch.inference_mode():\n","    for batch in pred_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        predictions = torch.argmax(outputs['logits'], dim=-1)\n","        pred_tensor = torch.cat((pred_tensor, predictions), dim=0)"],"metadata":{"id":"G3Z84ID62ynp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.3 Export results to a CSV file"],"metadata":{"id":"MBYpQyodXti0"}},{"cell_type":"code","source":["# Create a DataFrame with movie reviews and predicted labels for easy reference\n","import pandas as pd\n","unsupervised_reviews_df = pd.DataFrame(unsupervised_reviews)\n","unsupervised_reviews_df['label'] = pred_tensor.tolist()\n","unsupervised_reviews_df.to_csv('/content/drive/My Drive/Colab Notebooks/Movie_Review_Sentiment_Classify.csv', index=False)"],"metadata":{"id":"IyH3RL8STwyg"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6e7a6bc709534a55a1db9f83957a4ed0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b05fcef5a277453d8988a5085b5f1252","IPY_MODEL_897ac4eeffeb4f81a9804f919496a7c9","IPY_MODEL_6c02f4d1129d4548a6dff1789b4fe1a4"],"layout":"IPY_MODEL_74ea3b354bdd4aecac9fbc4cc661c0f4"}},"b05fcef5a277453d8988a5085b5f1252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08cc9c74ab974ff18514575ba33cd76d","placeholder":"​","style":"IPY_MODEL_e282efd44e874ff1a67f0e1d46de0ad3","value":"Map: 100%"}},"897ac4eeffeb4f81a9804f919496a7c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e5ec4c29c94143bd6490b073bb5ef7","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d34bd4e3a874d4480c325a09e6f7167","value":500}},"6c02f4d1129d4548a6dff1789b4fe1a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd9fcd2463c546eda6b5b66daf8b119e","placeholder":"​","style":"IPY_MODEL_325bedc92f6846b2995112ea9d0e4a05","value":" 500/500 [00:00&lt;00:00, 605.63 examples/s]"}},"74ea3b354bdd4aecac9fbc4cc661c0f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08cc9c74ab974ff18514575ba33cd76d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e282efd44e874ff1a67f0e1d46de0ad3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e5ec4c29c94143bd6490b073bb5ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d34bd4e3a874d4480c325a09e6f7167":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd9fcd2463c546eda6b5b66daf8b119e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325bedc92f6846b2995112ea9d0e4a05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"727eba7442e9405b92aeb14bb07c2b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b402c5a8635044d6bf44c66698468e0f","IPY_MODEL_379e725cc61043b684b4a155177d6cb9","IPY_MODEL_685ac324258a4d9da88a2f59f08d20cf"],"layout":"IPY_MODEL_03ce619f15624182af7f474d6711c4a6"}},"b402c5a8635044d6bf44c66698468e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fc03a6b0109409bbef2012f5ce79e30","placeholder":"​","style":"IPY_MODEL_50921b78d99d4948bdfd7415eba8c1a1","value":"Map: 100%"}},"379e725cc61043b684b4a155177d6cb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b11e883e01284b629964499ea6527eae","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80d1d6402474492ba5d8a7229cb5b8f5","value":500}},"685ac324258a4d9da88a2f59f08d20cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4750ff47eebe4abdb2a3977792c59c76","placeholder":"​","style":"IPY_MODEL_47fb460413cd474f8948b0c8137f15f8","value":" 500/500 [00:00&lt;00:00, 661.52 examples/s]"}},"03ce619f15624182af7f474d6711c4a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc03a6b0109409bbef2012f5ce79e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50921b78d99d4948bdfd7415eba8c1a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b11e883e01284b629964499ea6527eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d1d6402474492ba5d8a7229cb5b8f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4750ff47eebe4abdb2a3977792c59c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47fb460413cd474f8948b0c8137f15f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee013a12219c4d3ca421c2ab53c3c8b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92ff64710e10404690d1ca87d6120fe5","IPY_MODEL_23269ecb3b9145059b5b1a8426d219b4","IPY_MODEL_a1831eb7e5ee42c5a2235f33e02e719e"],"layout":"IPY_MODEL_7df80ba1301546e2a721bf32a0e63313"}},"92ff64710e10404690d1ca87d6120fe5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_433cbb3ab2664d2d921a3f93063f5d08","placeholder":"​","style":"IPY_MODEL_2847758316ab4ff0ba82f89af54d5674","value":""}},"23269ecb3b9145059b5b1a8426d219b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a14e5af82d6f4103858d1e62042d4d8d","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_447f139b18844fa89170951d780bdf2c","value":3}},"a1831eb7e5ee42c5a2235f33e02e719e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c999f6808acb4939b35d4b5a17bf7273","placeholder":"​","style":"IPY_MODEL_f49c79ffbe544bd99a900778cc1623cb","value":" 95/? [02:59&lt;00:00,  1.49s/it]"}},"7df80ba1301546e2a721bf32a0e63313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"433cbb3ab2664d2d921a3f93063f5d08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2847758316ab4ff0ba82f89af54d5674":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a14e5af82d6f4103858d1e62042d4d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"447f139b18844fa89170951d780bdf2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c999f6808acb4939b35d4b5a17bf7273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f49c79ffbe544bd99a900778cc1623cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae825b4b2d8c43cab6d7c91ba4a01ecb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b69c9d769d524f7a86b0471b3050217c","IPY_MODEL_f867218b067d422b9fc6a1b81372580d","IPY_MODEL_c7b4653313c1411995a5b538a9922284"],"layout":"IPY_MODEL_27577641e18f476a930e9ea2f06e4486"}},"b69c9d769d524f7a86b0471b3050217c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb89f8c7a74a441e98b92c235ce9d63c","placeholder":"​","style":"IPY_MODEL_9f27eb204fc94f998e0fb55a12fee00b","value":"Map: 100%"}},"f867218b067d422b9fc6a1b81372580d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f8cd7f9a4ca4ef7903ca7e3b952d39a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a3fd2a41236470692d93dd79d4deebc","value":1000}},"c7b4653313c1411995a5b538a9922284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fb7ea156697426fad7012cb4e9ca0fc","placeholder":"​","style":"IPY_MODEL_50e4f6a355df4659ab071a7a50789204","value":" 1000/1000 [00:01&lt;00:00, 708.89 examples/s]"}},"27577641e18f476a930e9ea2f06e4486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb89f8c7a74a441e98b92c235ce9d63c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f27eb204fc94f998e0fb55a12fee00b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f8cd7f9a4ca4ef7903ca7e3b952d39a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a3fd2a41236470692d93dd79d4deebc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fb7ea156697426fad7012cb4e9ca0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50e4f6a355df4659ab071a7a50789204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}